{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsE497sQDeax"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSGs2mBnDoUd"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('GAN')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3QYMeQ_iDrFd",
    "outputId": "aa1143cd-5d99-40a7-921c-8469d1148359"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "# load data\n",
    "(x_train, _),(x_test, _) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ROzf4N9XDtDW",
    "outputId": "857602ec-060c-4574-93c2-34d6e1fa618c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "# utility function\n",
    "import scipy\n",
    "import moviepy.editor as mpy\n",
    "def visualize_imgs(imgs, shape, save_path=None):\n",
    "    (row, col) = shape[0], shape[1]\n",
    "    height, width = imgs[0].shape[:2]\n",
    "    total_img = np.zeros((height*row, width*col))\n",
    "    for n, img in enumerate(imgs):\n",
    "        j = int(n/col)\n",
    "        i = n%col\n",
    "        total_img[j*height:(j+1)*height,i*width:(i+1)*width] = img\n",
    "    if save_path is not None:\n",
    "        scipy.misc.imsave(save_path, img)\n",
    "    return total_img\n",
    "  \n",
    "def make_gif(images, fname, duration=2, true_image=False):    \n",
    "    def make_frame(t):\n",
    "        try:\n",
    "            x = images[int(len(images)/duration*t)]\n",
    "        except:\n",
    "            x = images[-1]\n",
    "\n",
    "        if true_image:\n",
    "            return x.astype(np.uint8)\n",
    "        else:\n",
    "            return ((x+1)/2*255).astype(np.uint8)\n",
    "\n",
    "    clip = mpy.VideoClip(make_frame, duration=duration)\n",
    "    clip.write_gif(fname, fps = len(images) / duration)\n",
    "def iter_data(*data, **kwargs):\n",
    "    size = kwargs.get('batch_size', 128)\n",
    "    try:\n",
    "        n = len(data[0])\n",
    "    except:\n",
    "        n = data[0].shape[0]\n",
    "    batches = int(n / size)\n",
    "    if n % size != 0:\n",
    "        batches += 1\n",
    "    for b in range(batches):\n",
    "        start = b * size\n",
    "        end = (b + 1) * size\n",
    "        if end > n:\n",
    "            end = n\n",
    "        if len(data) == 1:\n",
    "            yield data[0][start:end]\n",
    "        else:\n",
    "            yield tuple([d[start:end] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-CisNKED1tW"
   },
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    def __init__(self, image_size, image_channel, z_dim=128, learning_rate=1e-4, lambda_=10):\n",
    "        self.image_size = image_size\n",
    "        self.image_channel = image_channel\n",
    "        self.z_dim = z_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_ = lambda_\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        if self.image_channel==1:\n",
    "            self.image_real = tf.placeholder(tf.float32,\n",
    "                                             [None, self.image_size, self.image_size])\n",
    "        else:\n",
    "            self.image_real = tf.placeholder(tf.float32,\n",
    "                                             [None, self.image_size,\n",
    "                                              self.image_size, self.image_channel])\n",
    "            \n",
    "        # create generator\n",
    "        self.image_fake = self.generator()\n",
    "        \n",
    "        # create discriminator and get its prediction for real/fake image\n",
    "        self.pred_real, self.logit_real = self.discriminator(self.image_real)\n",
    "        self.pred_fake, self.logit_fake = self.discriminator(self.image_fake)\n",
    "\n",
    "        # loss of discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                          logits=self.logit_real,\n",
    "                                          labels=tf.ones_like(self.logit_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                          logits=self.logit_fake,\n",
    "                                          labels=tf.zeros_like(self.logit_fake)))\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "\n",
    "        # loss of generator\n",
    "        self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                                          logits=self.logit_fake,\n",
    "                                          labels=tf.ones_like(self.logit_fake)))\n",
    "       \n",
    "        # create optimize operation for discriminator\n",
    "        self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "        self.d_update_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.d_loss,\n",
    "                                                                            var_list=self.d_vars)\n",
    "        \n",
    "        # create optimize operation for generator\n",
    "        self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "        self.g_update_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.g_loss,\n",
    "                                                                             var_list=self.g_vars)\n",
    "\n",
    "    def discriminator(self, image):\n",
    "        lrelu = tf.nn.leaky_relu\n",
    "        conv2d = tf.layers.conv2d\n",
    "        bn = tf.layers.batch_normalization\n",
    "        linear = tf.layers.dense    \n",
    "        with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "            if self.image_channel==1:\n",
    "                image = tf.reshape(image, [-1, self.image_size, self.image_size, 1])\n",
    "            hidden = self.z\n",
    "            hidden = image\n",
    "            hidden = lrelu(conv2d(hidden, 32, kernel_size=5, strides=2, padding='same'))\n",
    "            hidden = lrelu(bn(conv2d(hidden, 128, kernel_size=5, strides=2, padding='same'),\n",
    "                              training=True))\n",
    "            hidden = tf.layers.flatten(hidden)\n",
    "            hidden = lrelu(bn(linear(hidden, 1024), training=True))\n",
    "            hidden = linear(hidden, 1)\n",
    "            return tf.nn.sigmoid(hidden), hidden\n",
    "\n",
    "    def generator(self, y=None):\n",
    "        relu = tf.nn.relu\n",
    "        deconv2d = tf.layers.conv2d_transpose\n",
    "        bn = tf.layers.batch_normalization\n",
    "        linear = tf.layers.dense\n",
    "        with tf.variable_scope(\"generator\"):\n",
    "            self.z = tf.placeholder(tf.float32, [None, self.z_dim], name='z')\n",
    "            hidden = self.z\n",
    "            hidden = relu(bn(linear(hidden, 1024), training=True))\n",
    "            hidden = relu(bn(linear(hidden, (self.image_size//4)*(self.image_size//4)*128),\n",
    "                             training=True))\n",
    "            hidden = tf.reshape(hidden, [-1, self.image_size//4, self.image_size//4, 128])\n",
    "            hidden = relu(bn(deconv2d(hidden, 32, kernel_size=5, strides=2, padding='same'),\n",
    "                             training=True))\n",
    "            hidden = tf.nn.sigmoid(deconv2d(hidden, self.image_channel, kernel_size=5,\n",
    "                                            strides=2, padding='same'))\n",
    "            if self.image_channel==1:\n",
    "                hidden = tf.reshape(hidden, [-1, self.image_size, self.image_size])\n",
    "            return hidden\n",
    "          \n",
    "    def train(self, sess, x_train, num_epoch=100, batch_size=100, num_sample=100,\n",
    "              show_samples=True, sample_path='./samples', n_critic=2, log=False):\n",
    "        # sample some random noise, these noise is used to monitor generated image \n",
    "        sample_z = np.random.uniform(-1, 1, size=(num_sample , self.z_dim))\n",
    "        sample_imgs = []\n",
    "        \n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        d_loss_epoch = []\n",
    "        g_loss_epoch = []\n",
    "        for epoch in range(num_epoch):\n",
    "            shuffle_idx = np.random.permutation(len(x_train))\n",
    "            x_train = x_train[shuffle_idx]\n",
    "            d_losses = []\n",
    "            g_losses = []\n",
    "            for batch_images in iter_data(x_train, batch_size=batch_size):\n",
    "                batch_z = np.random.uniform(-1, 1,\n",
    "                                            [batch_size, self.z_dim]).astype(np.float32)\n",
    "                if counter % (n_critic+1) != 0:\n",
    "                    # Update D network\n",
    "                    feed_dict={ \n",
    "                        self.image_real: batch_images,\n",
    "                        self.z: batch_z,\n",
    "                    }\n",
    "                    d_loss, _ = sess.run([self.d_loss, self.d_update_op],\n",
    "                                         feed_dict=feed_dict)\n",
    "                    d_losses.append(d_loss)\n",
    "                else:\n",
    "                    # Update G network\n",
    "                    g_loss, _ = sess.run([self.g_loss, self.g_update_op],\n",
    "                                         feed_dict={self.z: batch_z})\n",
    "                    g_losses.append(g_loss)\n",
    "                counter += 1\n",
    "            if log:\n",
    "                print(\"Epoch: [{}] time: {:.2f}, d_loss: {:.4f}, g_loss: {:.4f}\".format(\n",
    "                      epoch, time.time()-start_time, np.mean(d_losses), np.mean(g_losses)))\n",
    "            d_loss_epoch.append(np.mean(d_losses))\n",
    "            g_loss_epoch.append(np.mean(g_losses))\n",
    "            \n",
    "            # save generated samples\n",
    "            samples = sess.run(self.image_fake, feed_dict={self.z: sample_z})\n",
    "            if not os.path.exists(sample_path):\n",
    "                os.makedirs(sample_path)\n",
    "            img = visualize_imgs(samples, shape=(10,20),\n",
    "                                 save_path=sample_path+'/epoch-{}.jpg'.format(epoch))\n",
    "            sample_imgs.append(img)\n",
    "                \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                if show_samples:\n",
    "                    plt.imshow(img, cmap = 'gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.title('epoch {}'.format(epoch+1))\n",
    "                    plt.show()\n",
    "        return sample_imgs, d_loss_epoch, g_loss_epoch\n",
    "      \n",
    "    def save_model(self, sess, checkpoint_dir='./checkpoints', model_name='model', step=None):\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver()\n",
    "        if step is not None:\n",
    "            saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
    "        else:\n",
    "            saver.save(sess, os.path.join(checkpoint_dir, model_name))\n",
    "        \n",
    "    def load_model(self, sess, checkpoint_dir='./checkpoints', model_name='model', step=None):\n",
    "        saver = tf.train.Saver()\n",
    "        if step is not None:\n",
    "            saver.save(sess, os.path.join(checkpoint_dir, model_name+'-{}'.format(step)))\n",
    "        else:\n",
    "            saver.save(sess, os.path.join(checkpoint_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inherit from DCGAN class\n",
    "class IWGAN(DCGAN):\n",
    "    def build_model(self):\n",
    "        if self.image_channel==1:\n",
    "            self.image_real = tf.placeholder(tf.float32,\n",
    "                                             [None, self.image_size, self.image_size])\n",
    "        else:\n",
    "            self.image_real = tf.placeholder(tf.float32,\n",
    "                                             [None, self.image_size,\n",
    "                                              self.image_size, self.image_channel])\n",
    "            \n",
    "        # create generator\n",
    "        self.image_fake = self.generator()\n",
    "        \n",
    "        # create discriminator and get its prediction for real/fake image\n",
    "        self.pred_real, self.logit_real = self.discriminator(self.image_real)\n",
    "        self.pred_fake, self.logit_fake = self.discriminator(self.image_fake)\n",
    "\n",
    "        # loss of discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(self.logit_real)\n",
    "        self.d_loss_fake = tf.reduce_mean(self.logit_fake)                        \n",
    "        self.d_loss = self.d_loss_fake - self.d_loss_real\n",
    "        \n",
    "        \n",
    "        ### Improved WGAN\n",
    "        BATCH_SIZE = tf.shape(self.image_fake)[0]\n",
    "        z = tf.random_uniform([BATCH_SIZE,1,1], 0.0, 1.0)\n",
    "        x_h = self.image_real * z + (1.0-z) * self.image_fake\n",
    "        dis_x_h = self.discriminator(x_h)\n",
    "        gradients = tf.gradients(dis_x_h[0], [x_h])[0]\n",
    "        ## L\n",
    "        self.slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1,2]))\n",
    "        gradient_penalty = tf.reduce_mean((self.slopes-1.0) ** 2)\n",
    "        self.d_loss += (self.lambda_ * gradient_penalty)\n",
    "\n",
    "        # loss of generator\n",
    "        self.g_loss = -tf.reduce_mean(self.logit_fake)\n",
    "       \n",
    "        # create optimize operation for discriminator\n",
    "        self.d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
    "        self.d_update_op = tf.train.AdamOptimizer(self.learning_rate,beta1=0.0,beta2=0.9).minimize(self.d_loss,\n",
    "                                                                        var_list=self.d_vars)\n",
    "        \n",
    "        # create optimize operation for generator\n",
    "        self.g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'generator')\n",
    "        self.g_update_op = tf.train.AdamOptimizer(self.learning_rate,beta1=0.0,beta2=0.9).minimize(self.g_loss,\n",
    "                                                                        var_list=self.g_vars)\n",
    "            \n",
    "    def train(self, sess, x_train, num_epoch=100, batch_size=100, \n",
    "              num_sample=100, show_samples=True, n_critic=2, \n",
    "              sample_path='./samples', log=False): \n",
    "    \n",
    "        # sample some random noise, these noise is used to monitor generated image \n",
    "        sample_z = np.random.uniform(-1, 1, size=(num_sample , self.z_dim))\n",
    "        sample_imgs = []\n",
    "        \n",
    "        counter = 1\n",
    "        start_time = time.time()        \n",
    "        d_loss_epoch = []\n",
    "        g_loss_epoch = []\n",
    "        for epoch in range(num_epoch):\n",
    "            shuffle_idx = np.random.permutation(len(x_train))\n",
    "            x_train = x_train[shuffle_idx]\n",
    "            d_losses = []\n",
    "            g_losses = []\n",
    "            for batch_images in iter_data(x_train, batch_size=batch_size):\n",
    "                batch_z = np.random.uniform(-1, 1,\n",
    "                                            [batch_size, self.z_dim]).astype(np.float32)\n",
    "                if counter % (n_critic+1) != 0:\n",
    "                    # Update D network\n",
    "                    feed_dict={ \n",
    "                        self.image_real: batch_images,\n",
    "                        self.z: batch_z,\n",
    "                    }\n",
    "                    d_loss, _, g = sess.run([self.d_loss, self.d_update_op,self.slopes],\n",
    "                                         feed_dict=feed_dict)\n",
    "                    d_losses.append(d_loss)\n",
    "                    #sess.run(self.weight_clip_ops)\n",
    "                else:\n",
    "                    # Update G network\n",
    "                    g_loss, _ = sess.run([self.g_loss, self.g_update_op],\n",
    "                                         feed_dict={self.z: batch_z})\n",
    "                    g_losses.append(g_loss)\n",
    "                counter += 1                                        \n",
    "            if log:\n",
    "                print(\"Epoch: [{}] time: {:.2f}, d_loss: {:.4f}, g_loss: {:.4f}\".format(\n",
    "                      epoch, time.time()-start_time, np.mean(d_losses), np.mean(g_losses)))\n",
    "            d_loss_epoch.append(np.mean(d_losses))\n",
    "            g_loss_epoch.append(np.mean(g_losses))\n",
    "            \n",
    "            # save generated samples\n",
    "            samples = sess.run(self.image_fake, feed_dict={self.z: sample_z})\n",
    "            if not os.path.exists(sample_path):\n",
    "                os.makedirs(sample_path)\n",
    "            img = visualize_imgs(samples, shape=(10,20),\n",
    "                                 save_path=sample_path+'/epoch-{}.jpg'.format(epoch))\n",
    "            sample_imgs.append(img)\n",
    "                \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                self.save_model(sess, step=counter)\n",
    "                if show_samples:\n",
    "                    plt.imshow(img, cmap = 'gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.title('epoch {}'.format(epoch+1))\n",
    "                    plt.show()\n",
    "        return sample_imgs, d_loss_epoch, g_loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(123)\n",
    "np.random.seed(123)\n",
    "iwgan = IWGAN(image_size=28, image_channel=1, learning_rate=5e-5)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "sample_imgs, d_loss_epoch, g_loss_epoch = iwgan.train(sess, x_train, num_sample=200, num_epoch=50, n_critic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.array(sample_imgs)\n",
    "make_gif(imgs*255., 'GAN/iwgan.gif', true_image=True, duration=2)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(url='GAN/iwgan.gif')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(d_loss_epoch)), d_loss_epoch, color = 'blue', label = 'd_loss')\n",
    "plt.plot(range(len(g_loss_epoch)), g_loss_epoch, color = 'red', label = 'g_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss of D & G')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications\n",
    "\n",
    "style transfer\n",
    "![](https://i.imgur.com/9wRW8fr.png)\n",
    "\n",
    "super resolution\n",
    "![](https://i.imgur.com/5vTbZdZ.jpg)\n",
    "\n",
    "Texture synthesis\n",
    "![](https://i.imgur.com/cZ3huwc.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I Learn:\n",
    "    \n",
    "I learn the architecture of GAN and WGAN and its improvment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab14_2_104062101.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
